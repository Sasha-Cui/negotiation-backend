Experiment design

• Unit of analysis: Each session involves an AI versus human negotiation matchup.  We record scenario_name, student_role, first_mover, AI agentic config, total_rounds, outcome, and demographic details.
• Treatments/conditions: AI agent configuration toggles (Base vs. Memory + Planning mode), role assignment (student as side1 or side2), and first-mover assignment (student vs. AI). These are tracked per session to allow comparative analysis.
• Scenarios: Two primary scenarios: Main_Street and Top_talent.  Main_Street is a single-issue price haggle case.  Top_talent is a multi-issue positive sum case.
• Outcomes and metrics: session outcomes (deal reached vs. failed/no deal/active), plus in-depth analytics on prices, rounds, and durations.  The Top_talent and Main_Street analyses also plan to compare performance across demographics and treatment assignments.



Preliminary findings.
1) Scenario coverage and volume
   • Main_Street: 156 sessions.
   • Top_talent: 138 sessions.

2) Configuration mix
   • Main_Street: 87 Base vs. 69 Agent.
   • Top_talent: all Agent.

3) LLMs have achieved superhuman level of negotiation capabilities.

4) LLMs lie to gain additional advantages in bargaining.